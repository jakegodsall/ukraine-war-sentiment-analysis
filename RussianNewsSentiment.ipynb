{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7daf177",
   "metadata": {},
   "source": [
    "# Russian News Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e108e",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f8268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 16:41:29.337844: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-23 16:41:29.337862: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# sci-kit learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# tf, keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import Sequential, Model\n",
    "from keras.layers import Input, Embedding, Bidirectional, MaxPooling1D\n",
    "from keras.layers import Dense, SpatialDropout1D, LSTM, Conv1D\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951d6e2",
   "metadata": {},
   "source": [
    "### File management and directory creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc5992d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.json\n",
      "data/test.json\n"
     ]
    }
   ],
   "source": [
    "# define Path object for data directory\n",
    "data_dir = Path('./data')\n",
    "\n",
    "# print data files\n",
    "for data_file in data_dir.glob('*'):\n",
    "    print(data_file)\n",
    "    \n",
    "# create directory for plots\n",
    "plots_dir = Path('./plots').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97ff725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8263, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Досудебное расследование по факту покупки ЕНПФ...</td>\n",
       "      <td>1945</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Медики рассказали о состоянии пострадавшего му...</td>\n",
       "      <td>1957</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Прошел почти год, как железнодорожным оператор...</td>\n",
       "      <td>1969</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>По итогам 12 месяцев 2016 года на территории р...</td>\n",
       "      <td>1973</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Астана. 21 ноября. Kazakhstan Today - Агентств...</td>\n",
       "      <td>1975</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    id sentiment\n",
       "0  Досудебное расследование по факту покупки ЕНПФ...  1945  negative\n",
       "1  Медики рассказали о состоянии пострадавшего му...  1957  negative\n",
       "2  Прошел почти год, как железнодорожным оператор...  1969  negative\n",
       "3  По итогам 12 месяцев 2016 года на территории р...  1973  negative\n",
       "4  Астана. 21 ноября. Kazakhstan Today - Агентств...  1975  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json(data_dir / 'train.json')\n",
    "test = pd.read_json(data_dir / 'test.json')\n",
    "\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "166f6aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting train dataset into X and y\n",
    "X, y = train['text'], train['sentiment']\n",
    "\n",
    "# encode y\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7303f6e",
   "metadata": {},
   "source": [
    "## RNN Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17d09e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "After tokenizing:\n",
      "\n",
      "X_train shape: (8263, 5000)\n",
      "y_train shape: (8263,)\n",
      "Before tokenizing:\n",
      "\n",
      "\n",
      "X_train shape: (6610, 5000)\n",
      "y_train shape: (6610,)\n",
      "X_val shape: (1653, 5000)\n",
      "y_val shape: (1653,)\n",
      "X_test shape: (2056,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X\n",
    "X_test = test['text']\n",
    "y_train = y\n",
    "\n",
    "max_words = 20000\n",
    "max_len = 5000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, split=' ',\n",
    "                      lower=True, filters='\\n\\t')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding='post')\n",
    "\n",
    "print(\"\\n\\nAfter tokenizing:\\n\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train, test_size=0.2)\n",
    "\n",
    "print(\"Before tokenizing:\\n\")\n",
    "print(f\"\\nX_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234a2b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedded_dimensions = 128\n",
    "lstm_out = 196\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedded_dimensions, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace2e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype\n",
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 128\n",
    "# history = model.fit(X_train,\n",
    "#                     y_train,\n",
    "#                     epochs=10,\n",
    "#                     batch_size=batch_size,\n",
    "#                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aba0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000\n",
    "max_len = 5000\n",
    "embedding_dim = 128\n",
    "class_num = 1\n",
    "lstm_out = 196\n",
    "\n",
    "\n",
    "def classifier(max_len, max_words, embedding_dim, class_num):\n",
    "    inputs = Input(shape=(max_len,))\n",
    "    embeddings = Embedding(max_words,\n",
    "                           embedding_dim,\n",
    "                           input_length=max_len)(inputs)\n",
    "    conv_1 = Conv1D(32, 9,\n",
    "                    activation='relu')(embeddings)\n",
    "    maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
    "    bilstm = Bidirectional(LSTM(32, dropout=0.2,\n",
    "                                recurrent_dropout=0.2,\n",
    "                                name='lstm_1'))(maxpool_1)\n",
    "    prediction = Dense(class_num, activation='sigmoid')(bilstm)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=prediction)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = classifier(max_len, max_words, embedding_dim, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59dcef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173259c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219983f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "max_len = 2000\n",
    "embedding_dim = 128\n",
    "class_num = 1\n",
    "lstm_out = 196\n",
    "\n",
    "def one_input_classifier(max_length, max_features, embedding_dim, class_num):\n",
    "    inputs = Input(shape=(max_length,), name='input_1')\n",
    "    embeddings = Embedding(max_features, embedding_dim, input_length=max_length, name='embedding_1')(inputs)\n",
    "\n",
    "    conv_1 = Conv1D(32, 9, activation='relu', name='conv1d_1')(embeddings)\n",
    "    maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
    "    dropout_1 = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
    "\n",
    "    conv_2 = Conv1D(32, 7, activation='relu', name='conv1d_2')(dropout_1)\n",
    "    maxpool_2 = MaxPooling1D(8, name='maxpool1d_2')(conv_2)\n",
    "    dropout_2 = Dropout(0.2, name='dropout_2')(maxpool_2)\n",
    "\n",
    "    bilstm = Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0.2, name='lstm_1'),\n",
    "        name='bidirectional_1')(dropout_2)\n",
    "    preds = Dense(class_num, activation='softmax', name='preds')(bilstm)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=preds)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = classifier(max_len, max_words, embedding_dim, class_num)\n",
    "\n",
    "batch_size = 32\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894dd244",
   "metadata": {},
   "source": [
    "# new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "max_words = 5000\n",
    "max_len = 2000\n",
    "embedding_dim = 128\n",
    "class_num = 1\n",
    "lstm_out = 196\n",
    "\n",
    "\n",
    "X_train, y_train = train['text'], train['sentiment']\n",
    "X_test = test['text']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "encoder = Tokenizer()\n",
    "encoder.fit_on_texts(X_train)\n",
    "\n",
    "X_train = encoder.texts_to_sequences(X_train)\n",
    "X_test = encoder.texts_to_sequences(X_test)\n",
    "\n",
    "max_length = max(map(len, X_train))\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_length)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "#y_test = np.array(y_test)\n",
    "\n",
    "embedding_dim = 4\n",
    "# print(x_train.shape[1], x_train.shape[2])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Create the model\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(len(encoder.index_word) + 1, embedding_dim))\n",
    "\n",
    "model.add(layers.LSTM(8, activation=\"tanh\",\n",
    "                      return_sequences=True, dropout=.2))\n",
    "\n",
    "model.add(layers.LSTM(8, activation=\"tanh\",\n",
    "                      return_sequences=False, dropout=.2))\n",
    "\n",
    "model.add(layers.Dense(3, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.build(input_shape=x_train.shape)\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train, epochs=25, shuffle=True,\n",
    "          batch_size=25, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc7e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09457d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
