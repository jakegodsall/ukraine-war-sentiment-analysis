{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bff9d1",
   "metadata": {},
   "source": [
    "# News Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15761b0",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "004e5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from core.preprocessing import NewsPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea181da9",
   "metadata": {},
   "source": [
    "### Defining paths and directory creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43c51184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.json\n",
      "data/test_cleaned.csv\n",
      "data/train_cleaned.csv\n",
      "data/test.json\n",
      "data/twitter_train.csv\n"
     ]
    }
   ],
   "source": [
    "# define Path object for data directory\n",
    "root_dir = Path('./')\n",
    "data_dir = root_dir / 'data'\n",
    "models_dir = root_dir / 'models'\n",
    "plots_dir = root_dir / 'plots'\n",
    "\n",
    "# print data files\n",
    "for data_file in data_dir.glob('*'):\n",
    "    print(data_file)\n",
    "    \n",
    "# create directory for plots and models\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "models_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9351c30",
   "metadata": {},
   "source": [
    "### Loading in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e242e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8263, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Досудебное расследование по факту покупки ЕНПФ...</td>\n",
       "      <td>1945</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Медики рассказали о состоянии пострадавшего му...</td>\n",
       "      <td>1957</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Прошел почти год, как железнодорожным оператор...</td>\n",
       "      <td>1969</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>По итогам 12 месяцев 2016 года на территории р...</td>\n",
       "      <td>1973</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Астана. 21 ноября. Kazakhstan Today - Агентств...</td>\n",
       "      <td>1975</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    id sentiment\n",
       "0  Досудебное расследование по факту покупки ЕНПФ...  1945  negative\n",
       "1  Медики рассказали о состоянии пострадавшего му...  1957  negative\n",
       "2  Прошел почти год, как железнодорожным оператор...  1969  negative\n",
       "3  По итогам 12 месяцев 2016 года на территории р...  1973  negative\n",
       "4  Астана. 21 ноября. Kazakhstan Today - Агентств...  1975  negative"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json(data_dir / 'train.json')\n",
    "test = pd.read_json(data_dir / 'test.json')\n",
    "\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93233b32",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80390e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = train['text'], train['sentiment'], test['text']\n",
    "\n",
    "processor = NewsPreprocessor(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4bd2ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_lowercase executed\n",
      "strip_punctuation executed\n",
      "remove_stopwords executed\n",
      "strip_special_chars executed\n",
      "remove_numbers executed\n",
      "stemmer executed\n",
      "label encoder executed\n"
     ]
    }
   ],
   "source": [
    "# preprocess X_train and store in train_cleaned.csv\n",
    "X_train = X_train.apply(lambda doc: processor.to_lowercase(doc))\n",
    "print(\"to_lowercase executed\")\n",
    "X_train = X_train.apply(lambda doc: processor.strip_punctuation(doc))\n",
    "print(\"strip_punctuation executed\")\n",
    "X_train = X_train.apply(lambda doc: processor.remove_stopwords(doc))\n",
    "print(\"remove_stopwords executed\")\n",
    "X_train = X_train.apply(lambda doc: processor.strip_special_chars(doc))\n",
    "print(\"strip_special_chars executed\")\n",
    "X_train = X_train.apply(lambda doc: processor.remove_numbers(doc))\n",
    "print(\"remove_numbers executed\")\n",
    "# processor.get_wordcount()\n",
    "# processor.get_freqwords(100)\n",
    "# X_train = X_train.apply(lambda doc: processor.remove_freqwords(doc))\n",
    "# print(\"remove_freqwords executed\")\n",
    "# processor.get_common_enough_words(3)\n",
    "# X_train = X_train.apply(lambda doc: processor.remove_rarewords(doc))\n",
    "# print(\"remove_rarewords executed\")\n",
    "X_train = X_train.apply(lambda doc: processor.stemmer(doc))\n",
    "print(\"stemmer executed\")\n",
    "y_train = processor.label_encoder()\n",
    "print(\"label encoder executed\")\n",
    "\n",
    "train_cleaned = pd.DataFrame({'text': X_train,\n",
    "                              'sentiment': y_train})\n",
    "\n",
    "train_cleaned.to_csv(data_dir / 'train_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d55f9018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_lowercase executed\n",
      "strip_punctuation executed\n",
      "remove_stopwords executed\n",
      "strip_special_chars executed\n",
      "remove_numbers executed\n",
      "stemmer executed\n"
     ]
    }
   ],
   "source": [
    "# preprocess X_test and store in test_cleaned.csv\n",
    "X_test = X_test.apply(lambda doc: processor.to_lowercase(doc))\n",
    "print(\"to_lowercase executed\")\n",
    "X_test = X_test.apply(lambda doc: processor.strip_punctuation(doc))\n",
    "print(\"strip_punctuation executed\")\n",
    "X_test = X_test.apply(lambda doc: processor.remove_stopwords(doc))\n",
    "print(\"remove_stopwords executed\")\n",
    "X_test = X_test.apply(lambda doc: processor.strip_special_chars(doc))\n",
    "print(\"strip_special_chars executed\")\n",
    "X_test = X_test.apply(lambda doc: processor.remove_numbers(doc))\n",
    "print(\"remove_numbers executed\")\n",
    "# processor.get_wordcount()\n",
    "# processor.get_freqwords(10)\n",
    "# X_test = X_test.apply(lambda doc: processor.remove_freqwords(doc))\n",
    "# print(\"remove_freqwords executed\")\n",
    "# processor.get_common_enough_words(3)\n",
    "# X_test = X_test.apply(lambda doc: processor.remove_rarewords(doc))\n",
    "# print(\"remove_rarewords executed\")\n",
    "X_test = X_test.apply(lambda doc: processor.stemmer(doc))\n",
    "print(\"stemmer executed\")\n",
    "\n",
    "test_cleaned = pd.DataFrame({'text': X_test})\n",
    "\n",
    "test_cleaned.to_csv(data_dir / 'test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9338d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'досудебное расследование факту покупки енпф пакета облигаций тоо бузгул аурум начато инициативе национального банка рк сообщил директор департамента защиты прав потребителей финансовых услуг нацбанка казахстана александр терентьев основанием досудебного расследования стало обращение национального банка письмо  ноября  года обращение национального банка правоохранительные органы нам эта сделка показалась сомнительной недостаточно корректной поэтому нацбанк  ноября  года обратился правоохранительные органы это могу озвучить сегодня идёт следствие проводится проверка – сказал терентьев  декабря нацбанке заявили знают стало основанием проверки енпф  декабря факт проведения проверки ао единый накопительный пенсионный фонд подтвердился прессслужба национального банка сообщила проверку проводят операциям совершённым ао енпф отношении инвестирования собственных активов также финрегуляторе сообщали сделке енпф сумму пять млрд заведено уголовное дело нацбанке заверяют всё происходящее затрагивает пенсионных накоплений казахстанцев нашли ошибку тексте выделите мышью нажмите ctrlenter '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30de9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
