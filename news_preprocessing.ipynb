{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c97dc1f6",
   "metadata": {},
   "source": [
    "# News Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35d692",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed5931",
   "metadata": {},
   "source": [
    "### Defining paths and directory creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15ec8c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.json\n",
      "data/test.json\n"
     ]
    }
   ],
   "source": [
    "# define Path object for data directory\n",
    "root_dir = Path('./')\n",
    "data_dir = root_dir / 'data'\n",
    "models_dir = root_dir / 'models'\n",
    "plots_dir = root_dir / 'plots'\n",
    "\n",
    "# print data files\n",
    "for data_file in data_dir.glob('*'):\n",
    "    print(data_file)\n",
    "    \n",
    "# create directory for plots and models\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "models_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718bdced",
   "metadata": {},
   "source": [
    "### Loading in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ee44e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8263, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Досудебное расследование по факту покупки ЕНПФ...</td>\n",
       "      <td>1945</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Медики рассказали о состоянии пострадавшего му...</td>\n",
       "      <td>1957</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Прошел почти год, как железнодорожным оператор...</td>\n",
       "      <td>1969</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>По итогам 12 месяцев 2016 года на территории р...</td>\n",
       "      <td>1973</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Астана. 21 ноября. Kazakhstan Today - Агентств...</td>\n",
       "      <td>1975</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    id sentiment\n",
       "0  Досудебное расследование по факту покупки ЕНПФ...  1945  negative\n",
       "1  Медики рассказали о состоянии пострадавшего му...  1957  negative\n",
       "2  Прошел почти год, как железнодорожным оператор...  1969  negative\n",
       "3  По итогам 12 месяцев 2016 года на территории р...  1973  negative\n",
       "4  Астана. 21 ноября. Kazakhstan Today - Агентств...  1975  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json(data_dir / 'train.json')\n",
    "test = pd.read_json(data_dir / 'test.json')\n",
    "\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afde8b4",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46310548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NewsPreprocessor at 0x7f2df3367730>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import stopwords as stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "class NewsPreprocessor:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.vocab = Counter()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def to_lowercase(self, doc):\n",
    "            \"\"\" \n",
    "            convert all text to lowercase and remove newline characters\n",
    "            \"\"\"\n",
    "            print(\"Running to_lowercase\")\n",
    "            return doc.lower().replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "\n",
    "    def strip_html_tags(self, doc):\n",
    "        \"\"\"\n",
    "        remove HTML tags from the text\n",
    "        \"\"\"\n",
    "        print(\"Running strip_html_tags\")\n",
    "\n",
    "        stripped_doc = []\n",
    "        for word in doc:\n",
    "            soup = BeautifulSoup(word, \"html.parser\")\n",
    "            stripped_word = soup.get_text()\n",
    "            stripped_doc.append(stripped_word)\n",
    "        return stripped_doc\n",
    "    \n",
    "    def strip_special_chars(self, doc):\n",
    "        \"\"\"\n",
    "        remove special characters from the text\n",
    "        \"\"\"\n",
    "        print(\"Running strip_special_characters\")\n",
    "        return re.sub(\"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\", \" \", doc)\n",
    "\n",
    "    def remove_stopwords(self, doc):\n",
    "        \"\"\"\n",
    "        remove stopwords from the text\n",
    "        \"\"\"\n",
    "        print(\"Running remove_stopwords\")\n",
    "        STOP = stopwords.words('russian')\n",
    "        words = doc.split(' ')\n",
    "        return ' '.join([word for word in words if word not in STOP])\n",
    "\n",
    "    def remove_numbers(self, doc):\n",
    "        \"\"\"\n",
    "        remove numbers from the text\n",
    "        \"\"\"\n",
    "        print(\"Running remove_numbers\")\n",
    "        return ''.join(i for i in doc if not i.isdigit())\n",
    "\n",
    "    def remove_freqwords(self, doc, num_words):\n",
    "        \"\"\"\n",
    "        remove the frequent words\n",
    "        \"\"\"\n",
    "        print(\"Running remove_freqwords\")\n",
    "        self.X_train.str.split().apply(self.vocab.update)\n",
    "        FREQWORDS = set([w for (w, wc) in self.vocab.most_common(num_words)])\n",
    "\n",
    "        return \" \".join([word for word in str(doc).split() if word not in FREQWORDS])\n",
    "\n",
    "    def remove_rarewords(doc, filter_val):\n",
    "        \"\"\"\n",
    "        remove the rare words\n",
    "        \"\"\"\n",
    "        print(\"Running remove_rarewords\")\n",
    "        self.X_train.str.split().apply(self.vocab.update)\n",
    "        RAREWORDS = []\n",
    "        for k, v in vocab_dict.items():\n",
    "            if v < 10:\n",
    "                RAREWORDS.append(k)\n",
    "        return \" \".join([word for word in str(doc).split() if word not in RAREWORDS])\n",
    "\n",
    "    \n",
    "\n",
    "# remove numbers\n",
    "# train.text = train.text.apply(lambda doc: ''.join(i for i in doc if not i.isdigit())) \n",
    "# test.text = test.text.apply(lambda doc: ''.join(i for i in doc if not i.isdigit())) \n",
    "\n",
    "    \n",
    "#train.text.apply(lambda doc: to_lowercase(doc))\n",
    "#train.text.apply(lambda doc: strip_html_tags(doc))\n",
    "#train.text.apply(lambda doc: remove_numbers(doc))\n",
    "#train.text.apply(lambda doc: remove_freqwords(doc))\n",
    "\n",
    "X_train, y_train = train['text'], train['sentiment']\n",
    "processor = NewsPreprocessor(X_train, y_train)\n",
    "\n",
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8679c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda doc: processor.to_lowercase(doc))\n",
    "X_train = X_train.apply(lambda doc: processor.remove_stopwords(doc))\n",
    "X_train = X_train.apply(lambda doc: processor.remove_numbers(doc))\n",
    "X_train = X_train.apply(lambda doc: processor.remove_freqwords(doc, 10))\n",
    "X_train = X_train.apply(lambda doc: processor.remove_rarewords(doc, 10))\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f94a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
