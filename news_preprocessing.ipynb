{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95e0d3c1",
   "metadata": {},
   "source": [
    "# News Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708171fe",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10444ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a33de",
   "metadata": {},
   "source": [
    "### Defining paths and directory creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46899885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.json\n",
      "data/test.json\n"
     ]
    }
   ],
   "source": [
    "# define Path object for data directory\n",
    "root_dir = Path('./')\n",
    "data_dir = root_dir / 'data'\n",
    "models_dir = root_dir / 'models'\n",
    "plots_dir = root_dir / 'plots'\n",
    "\n",
    "# print data files\n",
    "for data_file in data_dir.glob('*'):\n",
    "    print(data_file)\n",
    "    \n",
    "# create directory for plots and models\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "models_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df2f7a6",
   "metadata": {},
   "source": [
    "### Loading in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013d42c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8263, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Досудебное расследование по факту покупки ЕНПФ...</td>\n",
       "      <td>1945</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Медики рассказали о состоянии пострадавшего му...</td>\n",
       "      <td>1957</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Прошел почти год, как железнодорожным оператор...</td>\n",
       "      <td>1969</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>По итогам 12 месяцев 2016 года на территории р...</td>\n",
       "      <td>1973</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Астана. 21 ноября. Kazakhstan Today - Агентств...</td>\n",
       "      <td>1975</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    id sentiment\n",
       "0  Досудебное расследование по факту покупки ЕНПФ...  1945  negative\n",
       "1  Медики рассказали о состоянии пострадавшего му...  1957  negative\n",
       "2  Прошел почти год, как железнодорожным оператор...  1969  negative\n",
       "3  По итогам 12 месяцев 2016 года на территории р...  1973  negative\n",
       "4  Астана. 21 ноября. Kazakhstan Today - Агентств...  1975  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json(data_dir / 'train.json')\n",
    "test = pd.read_json(data_dir / 'test.json')\n",
    "\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d8974",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e99a97ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NewsPreprocessor at 0x7f2df3459090>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "class NewsPreprocessor:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.vocab = Counter()\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "        self.FREQWORDS = []\n",
    "        self.RAREWORDS = []\n",
    "        \n",
    "    def get_wordcount(self):\n",
    "        self.X_train.str.split().apply(self.vocab.update)\n",
    "\n",
    "    def get_freqwords(self, num_words):\n",
    "        FREQWORDS = set([w for (w, wc) in self.vocab.most_common(num_words)])\n",
    "    \n",
    "    def get_rarewords(self, filter_val):\n",
    "        vocab_dict = dict(self.vocab)\n",
    "        for k, v in vocab_dict.items():\n",
    "            if v < filter_val:\n",
    "                self.RAREWORDS.append(k)\n",
    "    \n",
    "    def to_lowercase(self, doc):\n",
    "            \"\"\" \n",
    "            convert all text to lowercase and remove newline characters\n",
    "            \"\"\"\n",
    "            return doc.lower().replace(\"\\r\", \" \").replace(\"\\n\", \" \")\n",
    "\n",
    "    def strip_html_tags(self, doc):\n",
    "        \"\"\"\n",
    "        remove HTML tags from the text\n",
    "        \"\"\"\n",
    "        stripped_doc = []\n",
    "        for word in doc:\n",
    "            soup = BeautifulSoup(word, \"html.parser\")\n",
    "            stripped_word = soup.get_text()\n",
    "            stripped_doc.append(stripped_word)\n",
    "        return stripped_doc\n",
    "    \n",
    "    def strip_special_chars(self, doc):\n",
    "        \"\"\"\n",
    "        remove special characters from the text\n",
    "        \"\"\"\n",
    "        # links\n",
    "        return re.sub(\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)|[«»]\", \" \", doc)\n",
    "\n",
    "    def remove_stopwords(self, doc):\n",
    "        \"\"\"\n",
    "        remove stopwords from the text\n",
    "        \"\"\"\n",
    "        STOP = stopwords.words('russian')\n",
    "        words = doc.split(' ')\n",
    "        return ' '.join([word for word in words if word not in STOP])\n",
    "\n",
    "    def remove_numbers(self, doc):\n",
    "        \"\"\"\n",
    "        remove numbers from the text\n",
    "        \"\"\"\n",
    "        return ''.join(i for i in doc if not i.isdigit())\n",
    "    \n",
    "    \n",
    "\n",
    "    def remove_freqwords(self, doc):\n",
    "        \"\"\"\n",
    "        remove the frequent words\n",
    "        \"\"\"\n",
    "        return \" \".join([word for word in str(doc).split() if word not in self.FREQWORDS])\n",
    "\n",
    "    def remove_rarewords(self, doc):\n",
    "        \"\"\"\n",
    "        remove the rare words\n",
    "        \"\"\"\n",
    "        return \" \".join([word for word in str(doc).split() if word not in self.RAREWORDS])\n",
    "\n",
    "    def stemmer(doc):\n",
    "        stemmer = SnowballStemmer(\"russian\")\n",
    "        return ' '.join([stemmer.stem(word) for word in doc.split(' ')])\n",
    "\n",
    "X_train, y_train = train['text'], train['sentiment']\n",
    "processor = NewsPreprocessor(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca09e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to_lowercase executed\n",
      "remove_stopwords executed\n",
      "strip_special_chars executed\n",
      "remove_numbers executed\n",
      "remove_freqwords executed\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.apply(lambda doc: processor.to_lowercase(doc))\n",
    "print(\"to_lowercase executed\")\n",
    "X_train = X_train.apply(lambda doc: processor.remove_stopwords(doc))\n",
    "print(\"remove_stopwords executed\")\n",
    "X_train = X_train.apply(lambda doc: processor.strip_special_chars(doc))\n",
    "print(\"strip_special_chars executed\")\n",
    "X_train = X_train.apply(lambda doc: processor.remove_numbers(doc))\n",
    "print(\"remove_numbers executed\")\n",
    "processor.get_wordcount()\n",
    "processor.get_freqwords(10)\n",
    "X_train = X_train.apply(lambda doc: processor.remove_freqwords(doc))\n",
    "print(\"remove_freqwords executed\")\n",
    "processor.get_rarewords(5)\n",
    "X_train = X_train.apply(lambda doc: processor.remove_rarewords(doc))\n",
    "print(\"remove_rarewords executed\")\n",
    "X_train = X_train.apply(lambda doc: preprocessor.stemmer(doc))\n",
    "print(\"stemmer executed\")\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2141ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
