{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67d3c42",
   "metadata": {},
   "source": [
    "# Ukraine War Sentiment Analysis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330bb34f",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "de43aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from time import time\n",
    "from datetime import datetime, date\n",
    "\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb301038",
   "metadata": {},
   "source": [
    "### Defining paths and directory creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "48e0cafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train.json\n",
      "data/test_cleaned.csv\n",
      "data/train_cleaned.csv\n",
      "data/test.json\n",
      "data/twitter_train.csv\n"
     ]
    }
   ],
   "source": [
    "# define Path object for data directory\n",
    "root_dir = Path('./')\n",
    "data_dir = root_dir / 'data'\n",
    "models_dir = root_dir / 'models'\n",
    "plots_dir = root_dir / 'plots'\n",
    "\n",
    "# print data files\n",
    "for data_file in data_dir.glob('*'):\n",
    "    print(data_file)\n",
    "    \n",
    "# create directory for plots and models\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "models_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22057d2f",
   "metadata": {},
   "source": [
    "### Loading in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0d538832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8263, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>досудебное расследование факту покупки енпф па...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>медики рассказали состоянии пострадавшего мужч...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>прошел год железнодорожным операторам запретил...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>итогам  месяцев  года территории республики вы...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>астана  ноября kazakhstan today  агентство рк ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  sentiment\n",
       "0           0  досудебное расследование факту покупки енпф па...          0\n",
       "1           1  медики рассказали состоянии пострадавшего мужч...          0\n",
       "2           2  прошел год железнодорожным операторам запретил...          0\n",
       "3           3  итогам  месяцев  года территории республики вы...          0\n",
       "4           4  астана  ноября kazakhstan today  агентство рк ...          0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(data_dir / 'train_cleaned.csv')\n",
    "test = pd.read_csv(data_dir / 'test_cleaned.csv')\n",
    "\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e730f",
   "metadata": {},
   "source": [
    "### Visualising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d7ff3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f01152b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average document: 436 words\n",
      "Longest document: 40554 words\n",
      "1 std above the mean: 500 words\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the number of words in each sample\n",
    "doc_len = train.text.apply(lambda doc: len(doc.split(' '))).to_numpy()\n",
    "max_words = 500\n",
    "\n",
    "# plot histogram\n",
    "sns.histplot(doc_len)\n",
    "plt.xlabel(\"Number of words\", fontsize=13)\n",
    "plt.ylabel(\"Count\", fontsize=13)\n",
    "\n",
    "print(f\"Average document: {int(doc_len.mean())} words\")\n",
    "print(f\"Longest document: {doc_len.max()} words\")\n",
    "print(f\"1 std above the mean: {max_words} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1618639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 6617\n",
      "Number of test examples: 1664\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# removing any documents with len(words) greater than 1 std dev from mean\n",
    "train = train[train.text.apply(lambda x: len(x.split(' '))) < max_words]\n",
    "test = test[test.text.apply(lambda x: len(x.split(' '))) < max_words]\n",
    "\n",
    "sns.histplot(train.text.apply(lambda x: len(x.split(' '))))\n",
    "plt.xlabel(\"Number of words\", fontsize=13)\n",
    "plt.ylabel(\"Count\", fontsize=13)\n",
    "\n",
    "print(f\"Number of training examples: {train.shape[0]}\")\n",
    "print(f\"Number of test examples: {test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "770993ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6617,)\n",
      "y_train shape: (6617,)\n",
      "\n",
      "X_test shape: (1664,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.text\n",
    "y_train = train.sentiment\n",
    "\n",
    "X_test = test.text\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"\\nX_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "40190385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words: 82732\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "vocab_count = Counter()\n",
    "\n",
    "X_train.str.split().apply(vocab_count.update)\n",
    "\n",
    "vocab_count = dict(vocab_count)\n",
    "\n",
    "print(f\"Number of distinct words: {len(vocab_count)}\")\n",
    "\n",
    "#sns.histplot(vocab_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "53d64097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut-off: 3\n",
      "Words included: 37175\n",
      "Words not included: 45557\n",
      "\n",
      "Cut-off: 5\n",
      "Words included: 26051\n",
      "Words not included: 56681\n",
      "\n",
      "Cut-off: 10\n",
      "Words included: 15799\n",
      "Words not included: 66933\n",
      "\n",
      "Cut-off: 20\n",
      "Words included: 9177\n",
      "Words not included: 73555\n",
      "\n",
      "Cut-off: 30\n",
      "Words included: 6500\n",
      "Words not included: 76232\n",
      "\n",
      "Cut-off: 40\n",
      "Words included: 5043\n",
      "Words not included: 77689\n",
      "\n",
      "Cut-off: 50\n",
      "Words included: 4050\n",
      "Words not included: 78682\n",
      "\n",
      "Cut-off: 100\n",
      "Words included: 2017\n",
      "Words not included: 80715\n",
      "\n",
      "Cut-off: 200\n",
      "Words included: 918\n",
      "Words not included: 81814\n",
      "\n",
      "Cut-off: 500\n",
      "Words included: 242\n",
      "Words not included: 82490\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = np.fromiter(vocab_count.values(), dtype=int)\n",
    "\n",
    "#sns.histplot(counts)\n",
    "for i in [3, 5, 10, 20, 30, 40, 50, 100, 200, 500]:\n",
    "    print(f\"Cut-off: {i}\")\n",
    "    common = counts[counts >= i]\n",
    "    print(f\"Words included: {len(common)}\\nWords not included: {len(counts) - len(common)}\\n\")\n",
    "\n",
    "#sns.histplot(counts[counts >= 10])\n",
    "plt.xlabel(\"Number of times a given word appears in text\", fontsize=13)\n",
    "plt.ylabel(\"Number of words\", fontsize=13)\n",
    "plt.xlim([0, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d71fd2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes classifier: 69.61%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "word_counts = cv.fit_transform(X_train)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(word_counts, \n",
    "                                                   y_train,\n",
    "                                                   test_size=0.25,\n",
    "                                                   random_state=666)\n",
    "\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(Xb_train, yb_train)\n",
    "\n",
    "predicted = mnb.predict(Xb_test)\n",
    "accuracy_score = metrics.accuracy_score(predicted, yb_test)\n",
    "print(f\"Accuracy of Naive Bayes classifier: {accuracy_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e28c48",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "86d32112",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'fit_resample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [250]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moversample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m(X_train, y_train)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'fit_resample'"
     ]
    }
   ],
   "source": [
    "oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7ca9fa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([371, 454, 16, 22, 317, 290, 64, 15, 7, 48, 83, 98, 411, 375, 275, 196, 183, 10, 466, 205, 64, 15, 63, 1, 64, 15, 266, 444, 167, 63, 1, 8, 31, 420, 5, 43, 35, 205, 16, 35, 320, 4, 489, 116, 125, 64, 15, 227, 4, 16, 152, 410, 86, 6, 16, 94, 477, 11, 383, 69, 392, 401, 485])\n",
      " list([277, 15, 211, 72, 14, 414, 87, 310, 376, 349, 414, 265, 228, 212, 3, 117, 14, 90, 14, 21, 130, 166, 21, 454, 449, 371, 7, 228, 420, 51, 4, 18, 12, 110, 15, 15, 129, 15, 168])\n",
      " list([32, 63, 206, 306, 255, 7, 239, 347, 227, 125, 405, 107, 154, 268, 111, 233, 329, 148, 75, 36, 206, 306, 42, 4, 112, 215, 75, 83, 30, 440, 481, 29, 110, 112, 450, 29, 112, 192, 4, 112, 299, 79, 112, 4, 103, 407, 478, 70, 442, 4, 252, 32, 4, 32, 4, 273, 4, 4, 194, 190, 4, 174, 29, 391, 161, 479, 205, 203, 336, 320, 6, 320, 148, 255, 80, 322, 442, 270, 270, 62, 122, 79, 270, 440, 446, 480, 70, 240, 29, 76, 60, 101, 255, 206, 306, 286, 261, 485])\n",
      " ...\n",
      " list([6, 235, 321, 363, 26, 444, 388, 218, 2, 427, 1, 8, 21, 257, 20, 119, 6, 9, 26, 150, 8, 212, 247, 26, 316, 462, 58, 8, 302, 384, 127])\n",
      " list([16, 300, 248, 65, 42, 65, 113, 226, 4, 16, 105, 67, 64, 15, 7, 51, 447, 272, 98, 64, 15, 170])\n",
      " list([14, 15, 31, 14, 130, 364, 15, 45, 5, 5, 364, 8, 310, 130, 164, 119, 15, 211, 117, 40, 153, 14, 15, 423, 176, 371, 7, 5, 265, 228, 56, 449, 7, 38, 89, 110, 8, 337, 15, 158])]\n",
      "6617 6617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_73153/304124059.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  encoded_docs = np.array(tokenizer.texts_to_sequences(X_train))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [253]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(encoded_docs), \u001b[38;5;28mlen\u001b[39m(y_train))\n\u001b[1;32m     11\u001b[0m oversample \u001b[38;5;241m=\u001b[39m imblearn\u001b[38;5;241m.\u001b[39mover_sampling\u001b[38;5;241m.\u001b[39mSMOTE()\n\u001b[0;32m---> 14\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43moversample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_docs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ukraine/lib/python3.10/site-packages/imblearn/base.py:77\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m check_classification_targets(y)\n\u001b[1;32m     76\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m---> 77\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/ukraine/lib/python3.10/site-packages/imblearn/base.py:132\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    130\u001b[0m     accept_sparse \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    131\u001b[0m y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 132\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[0;32m~/miniconda3/envs/ukraine/lib/python3.10/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/ukraine/lib/python3.10/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/ukraine/lib/python3.10/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "#preprocessing X_train\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "encoded_docs = np.array(tokenizer.texts_to_sequences(X_train))\n",
    "\n",
    "\n",
    "print(encoded_docs)\n",
    "print(len(encoded_docs), len(y_train))\n",
    "oversample = imblearn.over_sampling.SMOTE()\n",
    "\n",
    "\n",
    "X, y = oversample.fit_resample(encoded_docs, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7c7f2201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "4       0\n",
      "5       0\n",
      "6       0\n",
      "       ..\n",
      "8255    1\n",
      "8257    1\n",
      "8258    2\n",
      "8260    1\n",
      "8261    0\n",
      "Name: sentiment, Length: 6617, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder1 = LabelEncoder()\n",
    "# y_train = labelencoder_Y_1.fit_transform(y_train)\n",
    "\n",
    "# print(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f9c3b7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "4       0\n",
       "5       0\n",
       "6       0\n",
       "       ..\n",
       "8255    1\n",
       "8257    1\n",
       "8258    2\n",
       "8260    1\n",
       "8261    0\n",
       "Name: sentiment, Length: 6617, dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ed921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1549f968",
   "metadata": {},
   "source": [
    "# Model Saving Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "949126ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train, y_train, vocab_size, max_words):\n",
    "    tokenizer = Tokenizer(num_words=max_words, split=' ')\n",
    "    #preprocessing X_train\n",
    "    docs = X_train.to_numpy()\n",
    "    tokenizer.fit_on_texts(docs)\n",
    "    encoded_docs = tokenizer.texts_to_sequences(docs)\n",
    "    padded_docs = pad_sequences(encoded_docs, maxlen=max_words, padding='post')\n",
    "#     padded_docs, y_train = oversample(padded_docs, y_train)\n",
    "\n",
    "    # preprocessing y_train\n",
    "    encoder = LabelEncoder()\n",
    "    labels = to_categorical(y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return padded_docs, labels\n",
    "\n",
    "def oversample(X_train, y_train):\n",
    "    oversample = imblearn.over_sampling.SMOTE()\n",
    "    X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "    return X_train, y_train\n",
    "\n",
    "def fit_model(model, X_train, y_train, batch_size, num_epochs, val):\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              batch_size,\n",
    "              epochs=num_epochs,\n",
    "              validation_split=val)\n",
    "    \n",
    "def create_json(model, training_time):\n",
    "    \n",
    "    today = date.today()\n",
    "    now = datetime.now().time()\n",
    "    \n",
    "    model_json = {\n",
    "        \"Date\": today.strftime(\"%d/%m/%Y\"),\n",
    "        \"Time\": now.strftime(\"%H:%M:%S\"),\n",
    "        \"Name\": model.name,\n",
    "        \"Layers\": model.layers,\n",
    "        \"History\": model.history.history,\n",
    "        \"Layers\" : [{\"Name\": layer.name,\n",
    "                     \"Input\": str(layer.input),\n",
    "                     \"Output\": str(layer.output)} for layer in model.layers],\n",
    "        \"Vocab size\": vocab_size,\n",
    "        \"Embedding size\": embedding_size,\n",
    "        \"Max words\": max_words,\n",
    "        \"RNN units\": rnn_units,\n",
    "        \"Optimizer\": optimizer,\n",
    "        \"Epochs\": num_epochs,\n",
    "        \"Validation split:\": val,\n",
    "        \"Training time\": training_time\n",
    "    }\n",
    "    return model_json\n",
    "\n",
    "def plot_model(model):\n",
    "    \n",
    "    num_epochs = len(model.history.history['accuracy'])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4),\n",
    "                                  constrained_layout=True)    \n",
    "    ax1.plot(model.history.history['accuracy'])\n",
    "    ax1.plot(model.history.history['val_accuracy'])\n",
    "    ax1.set_title(\"Accuracy\", fontsize=13)\n",
    "    ax1.set_ylabel('Accuracy', fontsize=13)\n",
    "    ax1.set_xlabel('Number of epochs', fontsize=13)\n",
    "    ax1.set_xticks(range(0, num_epochs), range(1, num_epochs + 1))\n",
    "    ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    ax2.plot(model.history.history['loss'])\n",
    "    ax2.plot(model.history.history['val_loss'])\n",
    "    ax2.set_title(\"Loss\", fontsize=13)\n",
    "    ax2.set_ylabel('Loss', fontsize=13)\n",
    "    ax2.set_xlabel('Number of epochs', fontsize=13)\n",
    "    ax2.set_xticks(range(0, num_epochs), range(1, num_epochs + 1))\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    return fig\n",
    "    \n",
    "def train_and_save(name, X_train, y_train, model, batch_size, num_epochs, val):\n",
    "    # preprocess data\n",
    "    X_train, y_train = preprocess_data(X_train, y_train, vocab_size,\n",
    "                                    max_words)\n",
    "\n",
    "    start = time()\n",
    "    fit_model(model, X_train, y_train, batch_size, num_epochs, val)\n",
    "    training_time = time()-start\n",
    "    \n",
    "    model_json = create_json(model, training_time)\n",
    "\n",
    "    plots = plot_model(model)\n",
    "\n",
    "    plots.savefig(plots_dir / model_json['Name'])\n",
    "\n",
    "    with open(models_dir / (model_json[\"Name\"] + '.json'), 'w') as json_file:\n",
    "        json.dump(model_json, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "cfee7786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0   @user when a father is dysfunctional and is s...\n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2          3      0                                bihday your majesty\n",
       "3          4      0  #model   i love u take with u all the time in ...\n",
       "4          5      0             factsguide: society now    #motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
       "31958  31959      0    to see nina turner on the airwaves trying to...\n",
       "31959  31960      0  listening to sad songs on a monday morning otw...\n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961  31962      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_train = pd.read_csv(data_dir / 'twitter_train.csv')\n",
    "X_tweets = twitter_train['tweet']\n",
    "y_tweets = twitter_train['label']\n",
    "twitter_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ba4cb60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words: 67223\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "vocab_count = Counter()\n",
    "\n",
    "X_tweets.str.split().apply(vocab_count.update)\n",
    "\n",
    "vocab_count = dict(vocab_count)\n",
    "\n",
    "print(f\"Number of distinct words: {len(vocab_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "bc006979",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"lstm_base_model\"\n",
    "vocab_size = 60000\n",
    "embedding_size = 50\n",
    "max_words = 100\n",
    "rnn_units = 128\n",
    "optimizer = 'nadam, learning rate 0.0001'\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "val = 0.2\n",
    "\n",
    "\n",
    "model = Sequential(name=name)\n",
    "model.add(layers.Embedding(input_dim=vocab_size,\n",
    "                           output_dim=embedding_size,\n",
    "                           input_length=max_words, name=\"Embedding\"))\n",
    "#model.add(layers.Flatten())\n",
    "model.add(layers.LSTM(rnn_units, name=\"LSTM1\"))\n",
    "model.add(layers.Dense(2, activation='softmax', name=\"Dense\"))\n",
    "\n",
    "model.compile(tf.keras.optimizers.SGD(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save(name, X_tweets, y_tweets, model, batch_size, num_epochs, val)\n",
    "\n",
    "# train_and_save(name, test_x, test_y, 300,\n",
    "#                100, 300, 256, 'adam', 8, 30, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json(model):\n",
    "    \n",
    "    today = date.today()\n",
    "    now = datetime.now().time()\n",
    "    \n",
    "    model_json = {\n",
    "        \"Date\": today.strftime(\"%d/%m/%Y\"),\n",
    "        \"Time\": now.strftime(\"%H:%M:%S\"),\n",
    "        \"Name\": model.name,\n",
    "        \"Layers\": model.layers,\n",
    "        \"History\": model.history.history,\n",
    "        \"Layers\" : [{\"Name\": layer.name,\n",
    "                     \"Input\": str(layer.input),\n",
    "                     \"Output\": str(layer.output)} for layer in model.layers],\n",
    "        \"Vocab size\": vocab_size,\n",
    "        \"Embedding size\": embedding_size,\n",
    "        \"Max words\": max_words,\n",
    "        \"RNN units\": rnn_units,\n",
    "        \"Optimizer\": optimizer,\n",
    "        \"Epochs\": num_epochs,\n",
    "        \"Validation split:\": val\n",
    "    }\n",
    "    return model_json\n",
    "\n",
    "model_json = create_json(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f50ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(models_dir / (model_json[\"Name\"] + '.json'), 'w') as json_file:\n",
    "    json.dump(model_json, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daaf2cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165f5e79",
   "metadata": {},
   "source": [
    "### Training a base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451dd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words to consider in the vocabulary\n",
    "vocab_size = 1000\n",
    "\n",
    "# preprocessing X_train\n",
    "docs = X_train.to_numpy()\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_words, padding='post')\n",
    "\n",
    "# preprocessing y_train\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(y_train)\n",
    "\n",
    "print(f\"X_train shape: {padded_docs.shape}\")\n",
    "print(f\"y_train shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead4b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate=0.0001)\n",
    "\n",
    "rnn_out = 8\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 8, input_length=max_words))\n",
    "model.add(layers.Bidirectional(LSTM(rnn_out)))\n",
    "model.add(layers.LSTM(rnn_out))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44313884",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(padded_docs, labels, epochs=30, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1487e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel+('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eb94df",
   "metadata": {},
   "source": [
    "### Training with pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb3abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model_file = \"model/model.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_model_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word.split('_')[0]] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd523fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "\n",
    "t.fit_on_texts(X_train)\n",
    "\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "encoded_docs = t.texts_to_sequences(X_train)\n",
    "\n",
    "max_length = 200\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d64016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f92744",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3fbe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "opt = keras.optimizers.SGD(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e67e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out = 16\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "model.add(layers.Bidirectional(layers.LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(padded_docs, labels, epochs=20, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1907d40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9868baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model):\n",
    "    \n",
    "    num_epochs = len(model.history.history['accuracy'])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    \n",
    "    ax1.plot(model.history.history['accuracy'])\n",
    "    ax1.plot(model.history.history['val_accuracy'])\n",
    "    ax1.set_title(\"Accuracy\", fontsize=13)\n",
    "    ax1.set_ylabel('Accuracy', fontsize=13)\n",
    "    ax1.set_xlabel('Number of epochs', fontsize=13)\n",
    "    ax1.set_xticks(range(0, num_epochs), range(1, num_epochs + 1))\n",
    "    ax1.legend(['Train', 'Validation'], loc='upper left')\n",
    "    \n",
    "    ax2.plot(model.history.history['loss'])\n",
    "    ax2.plot(model.history.history['val_loss'])\n",
    "    ax2.set_title(\"Loss\", fontsize=13)\n",
    "    ax2.set_ylabel('Loss', fontsize=13)\n",
    "    ax2.set_xlabel('Number of epochs', fontsize=13)\n",
    "    ax2.set_xticks(range(0, num_epochs), range(1, num_epochs + 1))\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    return fig\n",
    "\n",
    "a = plot_model(test_model)\n",
    "\n",
    "a.savefig(plots_dir / test_model['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7cc70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
